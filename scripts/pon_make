#!/usr/bin/env python
import os
import sys
from os.path import isfile, join, dirname, abspath
import click
from os.path import join, dirname

from ngs_utils.call_process import run_simple
from ngs_utils.file_utils import verify_file, safe_mkdir, verify_dir
from ngs_utils import logger
from ngs_utils.logger import warn, info
from ngs_utils.snakemake_utils import run_snakemake
from ngs_utils.utils import set_locale; set_locale()
from ngs_utils import snakemake_utils
from vcf_stuff import _version as version
from vcf_stuff.panel_of_normals import package_path
from ngs_utils.file_utils import get_ungz_gz, splitext_plus, add_suffix, verify_file, safe_mkdir
from ngs_utils.bcbio import BcbioProject, NoConfigDirException, NoDateStampsException, MultipleDateStampsException
from ngs_utils.logger import warn
from vcf_stuff.panel_of_normals import package_path
from hpc_utils import hpc


@click.command()
@click.version_option(version.__version__)
@click.argument('normals_tsv', type=click.Path(exists=True))
@click.argument('target_rule', nargs=-1)
@click.option('-o', 'output_dir', type=click.Path(), help='Output directory [def: umccrised]')
@click.option('--genomes', '--genomes-dir', 'genomes_dir', help='Path to the reference data')

# Cluster:
@click.option('-j', '--jobs', 'jobs', default=1, help='Maximum number of cores to use at single time (works both for '
              'local and cluster runs)')
@click.option('-c', '--cluster-auto', 'cluster', is_flag=True, help='Submit jobs to cluster')

# Snakemake:
@click.option('--forcerun', 'forcerun', help='Comma-separated rules that will be run even if the outputs exist. Propagated to snakemake, space-separated.')
@click.option('--unlock', is_flag=True, help='Use when you are rerunning after Ctrl+C. Propagated to snakemake.')
@click.option('--restart-times', default=0, help='Propagated to snakemake. Default is 0.')
@click.option('-n', '--dryrun', 'dryrun', is_flag=True, help='Propagated to snakemake. Prints rules and commands '
                                                             'to be run without actually executing them.')
@click.option('--report', 'report', help='Propagated to snakemake. Create an HTML report with results and statistics. '
                                         'Needs to end in ".html".')
@click.option('--dag', 'dag', is_flag=True, help='Propagated to snakemake. Print the DAG of jobs in the dot language. '
                                                 'Usage: umccrise â€“-dag > tmp.txt; cat <cleaned-tmp.txt> | dot -Tsvg > dag.svg')

def main(normals_tsv, target_rule=list(), output_dir=None, test=False, genomes_dir=None,
         jobs=None, cluster=False,
         forcerun=None, unlock=False, restart_times=None, dryrun=False, report=None, dag=False):

    output_dir = output_dir or 'panel_of_normals'
    output_dir = safe_mkdir(abspath(output_dir))
    log_dir = safe_mkdir(join(output_dir, 'log'))
    logger.init(log_fpath_=join(log_dir, 'command.txt'), save_previous=True)

    bams_tsv = join(output_dir, 'bams.tsv')
    print('Finding normal BAM files')
    find_bams(normals_tsv, bams_tsv)

    conf = dict(bams_tsv=bams_tsv)
    if genomes_dir:
        conf['genomes_dir'] = verify_dir(genomes_dir, is_critical=True)

    ###########################
    #### Running snakemake ####
    ###########################

    snakefile = join(package_path(), 'make_pon.smk')
    run_snakemake(snakefile, conf, jobs, output_dir, log_dir=log_dir, cluster=cluster,
                  forcerun=forcerun, unlock=unlock, restart_times=restart_times,
                  dryrun=dryrun, report=report, dag=dag, target_rules=target_rule)


def find_bams(normals_tsv, bams_tsv):
    def _find_bcbio_run(bcbio_path):
        run = None

        def _find_handle_datestamps(bp):
            try:
                run = BcbioProject(bp, silent=True)
            except NoDateStampsException:
                warn(f'WARN: cannot parse bcbio run {bp} - no datestamp dir found')
            except MultipleDateStampsException:
                warn(f'WARN: cannot parse bcbio run {bp} - multiple datestamp dirs found')
            else:
                return run

        try:
            run = _find_handle_datestamps(bcbio_path)
        except NoConfigDirException:
            subdirs = os.listdir(bcbio_path)
            if len(subdirs) == 1:
                bcbio_path = join(bcbio_path, subdirs[0])
                try:
                    run = _find_handle_datestamps(bcbio_path)
                except NoConfigDirException:
                    warn(f'WARN: cannot parse bcbio run {bcbio_path} - no config dir')
        return run

    bam_by_sample = dict()

    with open(normals_tsv) as f:
        # reader = csv.DictReader(f, fieldnames=f.readline().strip().split('\t'), delimiter='\t')

        total_bcbio_runs = 0
        total_samples = 0
        cannot_read_project = 0
        found_normals = 0
        not_found_bam = 0

        for line in f:
            total_bcbio_runs += 1
            bcbio_path, sample_ids = line.strip().split('\t')
            sample_ids = set(sample_ids.split(','))
            total_samples += len(sample_ids)

            bcbio = _find_bcbio_run(bcbio_path)
            if not bcbio:
                cannot_read_project += 1
                continue
            normals = []
            for b in bcbio.batch_by_name.values():
                if b.normal:
                    if b.normal.name not in sample_ids:
                        print(f'WARN: {b.normal.name} not in requested normals.tsv samples for project {bcbio.final_dir}: {sample_ids}')
                    else:
                        normals.append(b.normal)
                        if b.normal.name == 'PRJ180156_1567_8073315T':
                            print('Found PRJ180156_1567_8073315T in normals in project ', bcbio.final_dir)
            if not normals:
                warn(f'WARN: not found normals in run {bcbio.final_dir}')
            for n in normals:
                if not n.bam or not verify_file(n.bam):
                    not_found_bam += 1
                    warn(f'WARN: not found BAM for normal {n.name}, run {bcbio.final_dir}')
                else:
                    found_normals += 1
                    bam_by_sample[n.name] = n.bam

    print(f'Done. From {total_bcbio_runs} bcbio, found {found_normals} normal VCFs from {total_samples} samples in normals.csv. '
          f'For {cannot_read_project} bcbio run(s), could not parse folder structure. '
          f'For {not_found_bam} sample(s), not found BAM file.')

    with open(bams_tsv, 'w') as out:
        for sn, bam in bam_by_sample.items():
            # symlink_bam = f'work/bam/{sn}.bam'
            # safe_mkdir(dirname(symlink_bam))
            # shell(f'ln -s {bam} {symlink_bam}')
            # shell(f'ln -s {bam}.bai {symlink_bam}.bai')
            out.write(f'{sn}\t{bam}\n')


if __name__ == '__main__':
    main()












